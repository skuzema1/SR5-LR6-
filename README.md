Кузема София

`Дисциплина: Методы и технологии машинного обучения`   
`Уровень подготовки: бакалавриат`   
`Направление подготовки: 01.03.02 Прикладная математика и информатика`   
`Семестр: осень 2022/2023`
# Лабораторная работа №6: Машины опорных векторов  
1.  Данные своего варианта из упражнения 3 (на регуляризацию и снижение размерности) разделила на выборку для построения моделей (90%) и отложенные наблюдения (10%).
Отложенные наблюдения использовать только для прогноза по лучшей модели.

![image](https://user-images.githubusercontent.com/93768556/207042793-9e676a5a-99d0-404e-b43e-2a91f02f1be2.png)

2. В качестве альтернативных моделей рассмотрим SVM с различными вариантами ядер и
логистическую регрессию. Причём предварительно преобразуем пространство исходных показателей с помощью метода главных компонент.  

#### Стандартизация и переход к главным компонентам
Доли объяснённой дисперсии по компонентам в PLS:
 [0.284 0.178 0.067 0.064 0.045 0.041 0.04  0.039 0.037 0.034 0.033 0.03
 0.025 0.023 0.017 0.011 0.011 0.008 0.006 0.003 0.002 0.001 0.001] 
Общая сумма долей: 1.0
Таким образом, первые две главные компоненты объясняют 46.2% разброса 23 объясняющих переменных. 
Теперь объединим функции-преобразователи и оценщики в конвейер с помощью Pipeline [https://scikit-learn.ru/6-1-pipelines-and-composite-estimators/] и оценим точность логистической регрессии с помощью перекрёстной проверки. конвейеры позволяет последовательно применять описанные преобразования. 

#### Модель логистической регрессии с перекрёстной проверкой
Acc с перекрёстной проверкой для модели sc_pca_logit :
0.798

####  SVM с перекрёстной проверкой
Построим несколько вариантов модели SVM с различными ядерными функциями.

Сеточный поиск занял
2040.93 секунд

Точность лучшей модели:
0.816

Параметры лучшей модели 

 * ядерная функция 
 'rbf'
 
 * параметр регуляризации 
 0.1
 
 * коэффициент ядерной функции (для ядер 'rbf', 'poly' и 'sigmoid') 
 0.1
 
 * степень полинома (для ядра 'poly') 
 3
 
3. Acc с перекрёстной проверкой для модели sc_pca_svc :
   0.816
   
4. Прогноз на отложенные наблюдения по лучшей модели
В данном случае модель SVM показывает большую точность, чем модель логистической регрессии.

Cводка по точности моделей

![image](https://user-images.githubusercontent.com/93768556/207046051-5d613e3a-1ab0-47be-946c-8193e90b685e.png)

Прогноз с помощью лучшей модели ансамбля с SVC

![image](https://user-images.githubusercontent.com/93768556/207046222-b2494128-551f-48cb-9a95-d85be2671482.png)
